# =============================================================================
# Docker Compose pour Aristote RAG Chatbot v2
# =============================================================================
# Usage:
#   docker-compose up -d          # Démarrer en arrière-plan
#   docker-compose logs -f app    # Voir les logs
#   docker-compose down           # Arrêter
#
# Avec Ollama (embeddings locaux):
#   docker-compose --profile ollama up -d
# =============================================================================

version: '3.8'

services:
  # ---------------------------------------------------------------------------
  # Application Streamlit
  # ---------------------------------------------------------------------------
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: aristote-rag-chatbot
    restart: unless-stopped

    ports:
      - "${STREAMLIT_PORT:-8501}:8501"

    volumes:
      # Volume persistant pour ChromaDB et les données utilisateur
      - aristote-data:/data
      # Optionnel: monter un fichier .env externe
      # - ./.env:/app/.env:ro

    environment:
      # === Providers ===
      - DEFAULT_EMBEDDING_PROVIDER=${DEFAULT_EMBEDDING_PROVIDER:-albert}
      - DEFAULT_LLM_PROVIDER=${DEFAULT_LLM_PROVIDER:-aristote}

      # === API Keys (depuis .env ou variables d'environnement) ===
      - ARISTOTE_API_KEY=${ARISTOTE_API_KEY}
      - ARISTOTE_API_BASE=${ARISTOTE_API_BASE:-https://llm.ilaas.fr/v1}
      - ALBERT_API_KEY=${ALBERT_API_KEY}
      - ALBERT_API_BASE=${ALBERT_API_BASE:-https://albert.api.etalab.gouv.fr/v1}

      # === Ollama (si utilisé) ===
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://ollama:11434}
      - OLLAMA_EMBEDDING_MODEL=${OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}

      # === Features optionnelles ===
      - RERANK_ENABLED=${RERANK_ENABLED:-false}
      - VISION_ENABLED=${VISION_ENABLED:-false}

      # === Authentification ===
      - AUTH_MODE=${AUTH_MODE:-none}
      - SESSION_SECRET=${SESSION_SECRET}

      # === Sécurité ===
      - MAX_FILE_SIZE=${MAX_FILE_SIZE:-10485760}
      - RATE_LIMIT_REQUESTS=${RATE_LIMIT_REQUESTS:-20}
      - RATE_LIMIT_WINDOW=${RATE_LIMIT_WINDOW:-60}

      # === Debug ===
      - DEBUG=${DEBUG:-false}

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

    networks:
      - aristote-network

    # Si Ollama est utilisé, dépendre du service
    # depends_on:
    #   ollama:
    #     condition: service_healthy

  # ---------------------------------------------------------------------------
  # Ollama (optionnel) - Pour embeddings locaux souverains
  # ---------------------------------------------------------------------------
  # Activer avec: docker-compose --profile ollama up -d
  ollama:
    image: ollama/ollama:latest
    container_name: aristote-ollama
    profiles:
      - ollama
    restart: unless-stopped

    volumes:
      - ollama-data:/root/.ollama

    ports:
      - "11434:11434"

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3

    networks:
      - aristote-network

    # Pour GPU NVIDIA (décommenter si disponible)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

# =============================================================================
# Volumes persistants
# =============================================================================
volumes:
  aristote-data:
    name: aristote-rag-data
    driver: local

  ollama-data:
    name: aristote-ollama-data
    driver: local

# =============================================================================
# Réseau
# =============================================================================
networks:
  aristote-network:
    name: aristote-network
    driver: bridge
